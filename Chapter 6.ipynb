{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Best Practice for Model Evaluation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter we will learn about followings:-\n",
    "\n",
    "- Obtain unbiased estimates of a model's performance\n",
    "- Diagnose the common problems of machine learning algorithms\n",
    "- Fine-tuning machine learning models\n",
    "- Evaluate predictive models using different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlining workflows with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wdbc.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "0     569 non-null int64\n",
      "1     569 non-null object\n",
      "2     569 non-null float64\n",
      "3     569 non-null float64\n",
      "4     569 non-null float64\n",
      "5     569 non-null float64\n",
      "6     569 non-null float64\n",
      "7     569 non-null float64\n",
      "8     569 non-null float64\n",
      "9     569 non-null float64\n",
      "10    569 non-null float64\n",
      "11    569 non-null float64\n",
      "12    569 non-null float64\n",
      "13    569 non-null float64\n",
      "14    569 non-null float64\n",
      "15    569 non-null float64\n",
      "16    569 non-null float64\n",
      "17    569 non-null float64\n",
      "18    569 non-null float64\n",
      "19    569 non-null float64\n",
      "20    569 non-null float64\n",
      "21    569 non-null float64\n",
      "22    569 non-null float64\n",
      "23    569 non-null float64\n",
      "24    569 non-null float64\n",
      "25    569 non-null float64\n",
      "26    569 non-null float64\n",
      "27    569 non-null float64\n",
      "28    569 non-null float64\n",
      "29    569 non-null float64\n",
      "30    569 non-null float64\n",
      "31    569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,2:].values\n",
    "y = df.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'M'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do label encoding of our classes\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([357, 212], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y) #classes ratio B and M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's split our dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining transformers and estimators in a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we have to standarize our data for logistic regression model since it uses gradient descent optimization, standarized of data helps in reaching minimum cost function early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will going to use pipeline in sklearn library it helps to chain a lot of process of machine learning on both our training set and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The make_pipeline function takes an arbitrary number of scikit-learn transformers(objects that support fit and transform method as inputs). Also make_pipeline function constructs a scikit-learn Pipeline object.<br>\n",
    "There is no limit to the number of intermediate steps in a pipeline; however the last pipeline element has to be an estimator(model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    StandardScaler(), PCA(n_components=2), LogisticRegression(random_state=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=2,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=1, solver='warn',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: {:.3}'.format(pipe_lr.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using k-fold cross validation to assess model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find an acceptable bias-variance trade-off, we need to evaluate our model carefully. **Cross-validation** help us obtain reliable estimates of the model's generalization performance i.e how well the model perform on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to discuss two cross validation technique here:-\n",
    "\n",
    "- Holdout cross validation\n",
    "- K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the holdout method, we split out initial dataset into training dataset and test dataset - the training dataset is used for training our model, and the test dataset is used to estimate model generalization performance.\n",
    "\n",
    "But we also have to do *model selection*, which refers to a given classification problem for which we want to select the optimal values of tuning parameters (also called hyperparameters).\n",
    "\n",
    "The problem is if we reuse the same test dataset over and over again during **model selection**, it will become part of our training data and thus the model will be more likely to overfit. Thus it is not fare to use test dataset for model selection and testing the model.\n",
    "\n",
    "A better way of using the holdout method for model selection is to separate the data into three parts:\n",
    "\n",
    "- A training set\n",
    "- A validation set\n",
    "- A test set\n",
    "\n",
    "The training set is use to fit the the different models.<br>\n",
    "The performance on the validation set is then used for the model selection<br>\n",
    "Now our test data is not yet exposed to our model, thus it is completely unseen by our model, hence it will be provide less biased estimate of model ability to generalize to a new data.\n",
    "\n",
    "A *Disadvantage* of the holdout method is that the performance estimate may be very sensitive to how we partition the training set and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In K-Fold cross-validation we randomly split the training dataset into k folds without replacement, where k-1 folds are used for the model training, and one fold is used for performance evaluation. This procedure is repeated k times so that we obtain k models and performance estimates.\n",
    "\n",
    "We then calculate the average performance of the models based on the different, independent folds to obtain a performance estimates that is less sensitive to the sub-partitioning of the training data compared to the holdout method.\n",
    "\n",
    "Typically we use k-fold cross validation for **model tuning**, i.e finding the optimal hyperparameter values that yields a satisfying generalization performance.\n",
    "\n",
    "Once we have found satisfactory hyperparmeter values, we can retrain the model on the complete training set and obtain a final performance estimate using the independent test set. We are doing training again after learning hyperparameter because it results in a more accurate and robust model.\n",
    "\n",
    "**Note:- A good standard value for *k* in K-fold cross validation is 10, as it has been suggested that it offers the best tradeoff between the bias and variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of k-fold cross validation is the **Leave-one-out cross validation (LOOCV)** method. In LOOCV, we set the number of folds equal to training samples (k=n) so that only one training sample is used for testing during each iteration, which is a recommended approach for working with very small datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement upon a K-fold cross validation is **Stratified K-fold cross validation**, which can yield better bias and variance estimates, especially in case of unequal class proportions. \n",
    "\n",
    "In stratified k-fold cross validation, <u>the class proportions are preserved in each fold</u> to ensure that each fold is representative of the class proportions in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=1).split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist:. [256 153], Acc: 0.935\n",
      "Fold: 2, Class dist:. [256 153], Acc: 0.935\n",
      "Fold: 3, Class dist:. [256 153], Acc: 0.957\n",
      "Fold: 4, Class dist:. [256 153], Acc: 0.957\n",
      "Fold: 5, Class dist:. [256 153], Acc: 0.935\n",
      "Fold: 6, Class dist:. [257 153], Acc: 0.956\n",
      "Fold: 7, Class dist:. [257 153], Acc: 0.978\n",
      "Fold: 8, Class dist:. [257 153], Acc: 0.933\n",
      "Fold: 9, Class dist:. [257 153], Acc: 0.956\n",
      "Fold: 10, Class dist:. [257 153], Acc: 0.956\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold): #spl\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    \n",
    "    print('Fold: {}, Class dist:. {}, Acc: {:.3}'.format(k+1, np.bincount(y_train[train]), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy 0.95 +/- 0.0139\n"
     ]
    }
   ],
   "source": [
    "print('CV accuracy {:.3} +/- {:.3}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also we use cross_val_score provided by scikit-learn to do above process, one benefit of using cross_val_score is the parameter n_jobs that helps us distributing works among processor, which do works parallely and thus execution time is less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(estimator=pipe_lr, X=X_train, y=y_train, cv = 10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy score [0.93478261 0.93478261 0.95652174 0.95652174 0.93478261 0.95555556\n",
      " 0.97777778 0.93333333 0.95555556 0.95555556]\n"
     ]
    }
   ],
   "source": [
    "print('CV accuracy score', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV average accuracy: 0.95 +/- 0.0139\n"
     ]
    }
   ],
   "source": [
    "print('CV average accuracy: {:.3} +/- {:.3}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging algorithms with learning and validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
